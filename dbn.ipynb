{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPDkfuMYsaNZyL50Z9JHKba",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabrizioaymone/DeepBeliefNetwork/blob/main/dbn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "KTrU7FzoJFgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist=keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "LJuhokoYt4Ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388120bb-a389-4b67-bc8a-2e37f8c5cdac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class rbm():\n",
        "  def __init__(self, learning_rate, batch_size, epochs):\n",
        "    self.toppen = np.random.normal(0, 1, (2000, 784))\n",
        "    self.toplab = np.random.normal(0, 1, (2000, 10))\n",
        "    self.learning_rate = learning_rate\n",
        "    self.batch_size = batch_size\n",
        "    self.epochs = epochs\n",
        "\n",
        "  def train(self, X_train, y_train):\n",
        "    size = X_train.shape[0]\n",
        "    for epoch in range(self.epochs):\n",
        "      print(\"Epoch number: \", epoch)\n",
        "      for batch in range(size//self.batch_size):\n",
        "        random_data_index = np.random.randint(X_train.shape[0], size=self.batch_size)\n",
        "        X_batch = X_train[random_data_index] \n",
        "        y_batch = np.eye(10)[y_train[random_data_index]]\n",
        "      \n",
        "        d_toppen = 0\n",
        "        d_toplab = 0\n",
        "        for i in range(self.batch_size):\n",
        "          #pos phase\n",
        "          lab_0 = y_batch[i]\n",
        "          pen_0 = X_batch[i, :]\n",
        "          top_0 = np.dot(pen_0, self.toppen.T) + np.dot(lab_0, self.toplab.T)\n",
        "          top_0 = self.sigmoid(top_0)\n",
        "          top_0 = top_0 > np.random.random_sample(len(top_0,))\n",
        "          #neg phase\n",
        "          lab_1 = np.dot(top_0, self.toplab)\n",
        "          pen_1 = np.dot(top_0, self.toppen)\n",
        "          lab_1 = self.softmax(lab_1)\n",
        "          pen_1 = self.sigmoid(pen_1)\n",
        "          lab_1 = np.eye(10)[np.random.choice(range(10), 1, p=lab_1)]\n",
        "          pen_1 = pen_1 > np.random.random_sample(len(pen_1,))\n",
        "          \n",
        "          top_1 = np.dot(pen_1, self.toppen.T) + np.dot(lab_1, self.toplab.T)\n",
        "          top_1 = self.sigmoid(top_1)\n",
        "          top_1 = top_1 > np.random.random_sample(len(top_1,))\n",
        "\n",
        "          d_toppen+= (np.outer(top_0, pen_0, ) - np.outer(top_1, pen_1))/self.batch_size\n",
        "          d_toplab+= (np.outer(top_0, lab_0) - np.outer(top_1, lab_1))/self.batch_size\n",
        "        \n",
        "        #weight update\n",
        "        self.toppen += self.learning_rate * d_toppen\n",
        "        self.toplab += self.learning_rate * d_toplab\n",
        "\n",
        "\n",
        "  def predict(self, x_train):\n",
        "    avg_lab = np.zeros(10)\n",
        "    for i in range(20):\n",
        "      lab_0 = np.full((10,), 0.1)\n",
        "      pen_0 = x_train\n",
        "\n",
        "      #alternating gibbs 1 reconstruction\n",
        "      top_0 = np.dot(pen_0, self.toppen.T) + np.dot(lab_0, self.toplab.T)\n",
        "      top_0 = self.sigmoid(top_0)\n",
        "      top_0 = top_0 > np.random.random_sample(len(top_0,))\n",
        "\n",
        "      lab_1 = np.dot(top_0, self.toplab)\n",
        "      lab_1 = self.softmax(lab_1)\n",
        "      avg_lab+=(lab_1/20)\n",
        "    return np.argmax(avg_lab)\n",
        "\n",
        "  def validate(self, X_val, y_val):\n",
        "    size = X_val.shape[0]\n",
        "\n",
        "    correct = 0\n",
        "    for i in range(size):\n",
        "      predicted = self.predict(X_val[i, :])\n",
        "      print(\"y: \",y_val[i],\" predicted: \", predicted)\n",
        "      if(y_val[i] == predicted):\n",
        "        correct+=1\n",
        "    \n",
        "    print(correct,\" correct on \",size,\" means accuracy of \",(correct/size*100),\"%\")\n",
        "\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    return 1/ (1 + np.exp(-x))\n",
        "  \n",
        "  def softmax(self, x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
      ],
      "metadata": {
        "id": "WwQf57gjkI-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full = X_train_full.reshape(X_train_full.shape[0], 784)\n",
        "X_test = X_test.reshape(X_test.shape[0], 784)\n",
        "\n",
        "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test/255.0"
      ],
      "metadata": {
        "id": "0Nw-GdChkMad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try\n",
        "model = rbm(0.1, 10, 30)\n",
        "num = 10\n",
        "X_try = X_train[1000:num+1000]\n",
        "y_try = y_train[1000:num+1000]\n",
        "model.train(X_try, y_try)\n",
        "model.validate(X_try, y_try)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-p64_pupRlE",
        "outputId": "119934c1-5ac6-49d1-cf81-a483147e0290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch number:  0\n",
            "Epoch number:  1\n",
            "Epoch number:  2\n",
            "Epoch number:  3\n",
            "Epoch number:  4\n",
            "Epoch number:  5\n",
            "Epoch number:  6\n",
            "Epoch number:  7\n",
            "Epoch number:  8\n",
            "Epoch number:  9\n",
            "Epoch number:  10\n",
            "Epoch number:  11\n",
            "Epoch number:  12\n",
            "Epoch number:  13\n",
            "Epoch number:  14\n",
            "Epoch number:  15\n",
            "Epoch number:  16\n",
            "Epoch number:  17\n",
            "Epoch number:  18\n",
            "Epoch number:  19\n",
            "Epoch number:  20\n",
            "Epoch number:  21\n",
            "Epoch number:  22\n",
            "Epoch number:  23\n",
            "Epoch number:  24\n",
            "Epoch number:  25\n",
            "Epoch number:  26\n",
            "Epoch number:  27\n",
            "Epoch number:  28\n",
            "Epoch number:  29\n",
            "y:  8  predicted:  8\n",
            "y:  6  predicted:  5\n",
            "y:  4  predicted:  5\n",
            "y:  4  predicted:  4\n",
            "y:  6  predicted:  3\n",
            "y:  5  predicted:  5\n",
            "y:  5  predicted:  5\n",
            "y:  8  predicted:  8\n",
            "y:  7  predicted:  7\n",
            "y:  3  predicted:  5\n",
            "6  correct on  10  means accuracy of  60.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1SSl3LuL6WSB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}